{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c60c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786e651531e749a9a298d5fdef60b4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9fa7b4b37f49edab2d53c84a9ac5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9031999707221985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "train_data = datasets.MNIST(root=\"./dataset\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root=\"./dataset\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "logistic_regression_model = nn.Linear(784, 10)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(logistic_regression_model.parameters(), lr=0.1)\n",
    " \n",
    "for images, labels in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    x = images.view(-1, 784)\n",
    "    y = logistic_regression_model(x)\n",
    "    loss = criterion(y, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "correct = 0\n",
    "n = len(test_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        x = images.view(-1,784)\n",
    "        y = logistic_regression_model(x)\n",
    "        prediction = torch.argmax(y,dim=1)\n",
    "        correct+=torch.sum((prediction==labels).float())\n",
    "\n",
    "print(\"Accuracy = {}\".format(correct/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e64c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cells below this cell are for checking visually how our model performs\n",
    "# add index to load image and label in MNIST test_data\n",
    "# you will get the image and true label corresponding to the image\n",
    "# after running the next cell you will get the label predicted by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "384faf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true lable: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im,lb = test_data[6]\n",
    "im = im.reshape([28,28])\n",
    "plt.imshow(im, cmap='gray')\n",
    "print(\"true lable: {}\".format(lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd614062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label: tensor([4])\n"
     ]
    }
   ],
   "source": [
    "x = im.view(-1,784)\n",
    "y = logistic_regression_model(x)\n",
    "prediction = torch.argmax(y,dim=1)\n",
    "print(\"predicted label: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253cfed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
